<!doctype html>
<html>
  <head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
    <meta charset="utf-8">
    <title></title>
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#4285f4">
    <meta property="og:url" content="https://webmusicdevelopers.appspot.com/codelabs/webaudio/index.html" />
    <meta property="og:title" content="Web Audio API - Codelab" />
    <meta property="og:image" content="https://webmusicdevelopers.appspot.com/codelabs/webaudio/images/webaudio-js-144x144.png" />
    <meta property="og:description" content="This is a codelab for Web Audio API." />
    <meta property="og:site_name" content="Web Audio API - Codelab" />
    <link rel="manifest" href="./manifest.json">
    <link rel="stylesheet" href="./css/main.css" type="text/css" />
    <link rel="stylesheet" href="./bower_components/highlightjs/styles/railscasts.css" type="text/css" />

    <link rel="import" href="./components/import.html">
    <script src="./bower_components/webcomponentsjs/webcomponents-lite.js"></script>
    <link href="//fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <style>
    .material-icons {
      color: rgba(140, 140, 140, 1);
    }
    div.sample-input-01-blue {
      background-color:rgb(237, 244, 255);
      border-left: 4px solid #94BAF9;
      padding:0.4em;
      margin:1.0em;
    }
    canvas.step7 {
      background-color:rgba(34, 34, 34, 1.0);
      border-radius:3px;
    }
    </style>
  </head>

  <body unresolved>

    <codelab-pack label="Web Audio API" 
                  feedback_link="https://github.com/ryoyakawai/x-webmidi/issues"
                  category=""
                  environment="">

      <!-- 1 -->
      <codelab-article step_label="はじめに" duration="1:00">
        <h2>利用背景</h2>
        <p class="top">ここでは、WebAudioの基本的な機能について実装をしながら学んでいきます。</p>
        
        <h2>実装に使うもの</h2>
        <ul class="top">
          <li><img src="./images/chrome_flat_by_packrobottom.png" width="16px" class="middle"><a href="//www.google.co.jp/chrome/browser/" target="_blank">Google Chrome</a> 43+</li>
          <li><img src="./images/chrome_dev_editor-logo.png" width="16px" class="middle"><a href="https://chrome.google.com/webstore/detail/chrome-dev-editor-develop/pnoffddplpippgcfjdhbmhkofpnaalpg" target="_blank">Chrome Dev Editor</a></li>
        </ul>
        <!--
        <h2>完成品ソースコード</h2>
        <ul class="top" style="list-style-type: none">
          <li><i class="material-icons middle">file_download</i><a href="./download/">ソースコード</a></li>
        </ul>        
        -->
      </codelab-article>

      <!-- 2 -->
      <codelab-article step_label="開発環境の準備" duration="1:00">
        <h2><img src="./images/chrome_flat_by_packrobottom.png" width="20" class="middle">Google Chromeのインストール</h2>
        <p class="top">ご利用のPlatformに合わせて<a href="//www.google.co.jp/chrome/browser/" target="_blank">ココ</a>からダウンロードしてご利用ください。</p>

        <h2><img src="./images/chrome_dev_editor-logo.png" width="20" class="middle">Chrome Dev Editorのインストール</h2>
        <p class="top"><a href="//chrome.google.com/webstore/detail/chrome-dev-editor-develop/pnoffddplpippgcfjdhbmhkofpnaalpg" target="_blank">ココ</a>をChromeで表示してインストールしてください。</p>

        <h2><i class="material-icons middle">folder_open</i>アプリケーションを開発するディレクトリの作成</h2>
        <p>Chrome Dev Editorを起動します。<br><code>chrome://apps</code>からアプリケーションランチャーを表示して、<b>Chrome Dev Editor</b>をクリックでChrome Dev Editorは起動します。
          <div class="flex-center">
            <img src="./images/webaudio-launch.png" width="420" class="bordered">
          </div>
        </p>
        <p>
            起動後画面の左ペイン右下の <i class="material-icons middle" style="color:rgba(210, 63, 49, 1);">add_circle</i>ボタンをクリックして、表示されるダイアログの<span class="input-font">[CHOOSE FOLDER]</span>を選択して、開発用ディレクトリを指定します。<br>
          <span class="notice-01">※ 初期起動の場合プロジェクト名・Type指定の前に保存するディレクトリの指定画面が表示されます。ここでは<span class="input-font">~/Documents/chrome_dev_editor/</span>と指定しています。</span> 
          <div class="flex-center">
            <img src="./images/webaudio-00.png" width="420" class="bordered">
          </div>
          <p style="margin-bottom:2px;">ここではサンプルとして以下を入力・選択しています。</p>
          <div class="sample-input-01-blue" style="margin-top:2px;">
              Project Name: <span class="input-font">test_webaudioapi</span><br>
              Project type: <span class="input-font">JavaScript web app</span>
          </div>
        </p>

      </codelab-article>

      <!-- 3 -->
      <codelab-article step_label="音を出してみる" duration="5:00">
        <p>Oscillator Nodeを使って音を出してみます。</p>

        <p>まずは以下のコードを <span class="input-font">index.html</span> に追記してください。</p>

        <codelab-snippet>
&lt;button onclick="Play()">Play&lt;/button>
&lt;script type="text/javascript">
var audioctx = new AudioContext();
var osc = audioctx.createOscillator();
osc.connect(audioctx.destination);
function Play() {
  osc.start(0);
}
&lt;/script></codelab-snippet>
        
        <p>Chrome Dev Editorの左上の再生ボタン <i class="material-icons middle">play_arrow</i> をクリックすると実行されます。</p>
        <div class="flex-center">
          <img src="./images/webaudio-01.png" width="520" class="bordered">
        </div>

        <p>アプリケーションを実行し、実行画面内の<button id="step3">Play</button> ボタンを押して音が鳴れば完成です。ちなみに、音を停止する部分の実装はしていませんの、止める場合はブラウザの画面をリロードしてください。</p>

        <p>以下の流れで Node Graph を作っています。</p>
        <ul style="list-style-type: decimal">
          <li><code>new AudioContext();</code> AudioContext を作る</li>
          <li><code>audioctx.createOscillator();</code> オシレータ（発振機：音の素）を作成する</li>
          <li><code>osc.connect(audioctx.destination);</code> Node Graph を完成させる（<span class="input-font">destination</span> に接続する）</li>
          <li>ボタン操作により、オシレータを発動させる</li>
        </ul>

        <p>ここでオシレータはWeb Audio APIの最小単位で Node と呼びます。この他にも、多くの Node が用意されており、それらの Node をつなげることで Node Graph を作り音を作っていくところが Web Audio API の特徴です。</p>
        <p>またNode Graphの終端を <span class="input-font">destination</span> と呼びます。AudioContext 作成時に自動生成される Node で、これにつなげることで音になります。</p>
        <p>Web Audio API では Node をつなぎ合わせ、Node Graph を作成して、音を作っていきます。</p>

        <p>ちなみに、ここでは以下のような Node Graph を作ったことになります。</p>
        <div class="flex-center">
          <img src="./images/osc1.png" class="bordered">
        </div>
        <p><span class="notice-01">※ 以後はアプリケーションの実行方法の説明は省略します。</span></p>
      </codelab-article>


      <!-- 4 -->
      <codelab-article step_label="オシレータを揺らしてみる" duration="5:00">

        <p>オシレータだけでは単調な音しかなりませんので、ここでは試しにオシレータを揺らしてみます。</p>
        <p>前の Step で追加したコードを <span class="input-font">index.html</span> から削除して、以下のコードを追記してください。</p>
        <codelab-snippet>
&lt;table>
  &lt;tr>&lt;td>LFO Freq : &lt;/td>&lt;td>&lt;input type="text" size="10" id="lfofreq" value="5"/>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>Depth : &lt;/td>&lt;td>&lt;input type="text" size="10" id="depth" value="10"/>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>VCO Freq : &lt;/td>&lt;td>&lt;input type="text" size="10" id="vcofreq" value="440"/>&lt;/td>&lt;/tr>
&lt;/table>
&lt;br/>
&lt;button onclick="Setup()">Set&lt;/button>&lt;br/>
&lt;script type="text/javascript">
var audioctx = new AudioContext();
var play = 0;
var vco = audioctx.createOscillator();
var lfo = audioctx.createOscillator();
var depth = audioctx.createGain();
vco.connect(audioctx.destination);
lfo.connect(depth);
depth.connect(vco.frequency); // &lt;== connect to frequency parameter of vco
function Setup() {
  if(play == 0) {
    play = 1;
    vco.start(0);
    lfo.start(0);
  }
  vco.frequency.value = parseFloat(document.getElementById("vcofreq").value);
  lfo.frequency.value = parseFloat(document.getElementById("lfofreq").value);
  depth.gain.value = parseFloat(document.getElementById("depth").value);
}
&lt;/script></codelab-snippet>
        
        <p class="bottom5px">アプリケーションを実行し、実行画面内の <button id="step4">Set</button> ボタンを押して音が鳴り、更に画面内のパラメータを変更して <button id="step4-set">Set</button> ボタンを押すことで、音の揺らぎが変化すれば完成です。</p>
        <ul class="top">
          <li><span class="input-font">VCO Freq = <span id="step4vcofreq">440</span></span></li> 
          <li><span class="input-font">LFO Freq = <span id="step4lfofreq">5</span></span></li>
          <li><span class="input-font">Depth = <span id="step4depth">10</span></span></li>
        </ul>
        <p class="bottom5px">新しい言葉が出て来たのでその説明です。</p>
        <ul class="top">
          <li><span class="input-font">VCO</span> ： Voltage-Controlled Oscillator 電圧で発信周波数を制御する音の素となるオシレータ</li>
          <li><span class="input-font">LFO</span> ： Low Frequency Oscillator 低い周波数の揺らぎを与えるオシレータ</li>
        </ul>

        <p>基本的なアイデアは、音の素となるオシレータの周波数を揺らぎを与えるオシレータを接続しオシレータに揺らぎを与えることで、音全体にも揺らぎを与えます。またその揺らぎの幅を <span class="input-font">depth</span> というパラメータで調節します。</p>
        <p>Node Graph の説明をします。</p>
        <ul style="list-style-type: decimal">
          <li><code>new AudioContext();</code> AudioContext を作る</li>
          <li><code>audioctx.createOscillator();</code> 音の素となるオシレータを作成する</li>
          <li><code>audioctx.createOscillator();</code> 揺らぎを与えるオシレータを作成する</li>
          <li><code>audioCtx.createGain();</code> 揺らぎを与えるオシレータの揺らぎの幅を調節する Node を作成する</li>
          <li><code>vco.connect(audioctx.destination);</code> <span class="input-font">audioctx.destination</span> に接続し Node Graph を完成させる</li>
          <li><code>lfo.connect(depth);</code> 揺らぎを与えるオシレータの幅を調整する為の Node と接続する</li>
          <li><code>depth.connect(vco.frequency);</code> 揺らぎを与えるオシレータの音の素となる Node の周波数に接続する</li>
          <li>ボタン操作により、オシレータを発動、またパラメータの更新を行う</li>
        </ul>

        <p>ここでは以下のような Node Graph を作ったことになります。</p>
        <div class="flex-center">
          <img src="./images/vibrato.png" class="bordered">
        </div>
        <br>
      </codelab-article>


      <!-- 5 -->
      <codelab-article step_label="オーディオファイルを鳴らす" duration="7:00">
        <p><a href="contents/snare.wav"><span class="input-font">snare.wav</span></a> をダウンロードして Chrome Dev Editor の左ペイン内のプロジェクト名（ここでは test_webaudioapi）にドロップしてください。</p>
        <div class="flex-center">
          <img src="./images/webaudio-02.png" width="580" class="bordered">
        </div>

        <p>次に、前の Step で追加したコードを <span class="input-font">index.html</span> から削除して、以下のコードを追記してください。</p>
        <codelab-snippet>
&lt;button onclick="Play()" id="playsound" disabled>Play&lt;/button>
&lt;script type="text/javascript">
var audioctx = new AudioContext();
var buffer = null;
LoadSample(audioctx, "./snare.wav");
function Play() {
  var src = audioctx.createBufferSource();
  src.buffer = buffer;
  src.connect(audioctx.destination);
  src.start(0);
}
function LoadSample(ctx, url) {
  var req = new XMLHttpRequest();
  req.open("GET", url, true);
  req.responseType = "arraybuffer";
  req.onload = function() {
    if(req.response) {
      ctx.decodeAudioData(req.response,function(b){buffer=b;},function(){});
      document.querySelector("button#playsound").removeAttribute("disabled");
    }
  }
  req.send();
}
&lt;/script></codelab-snippet>
        
        <p>アプリケーションを実行し、実行画面内の <button id="step5">Play</button> ボタンをクリックするとスネアドラムの「パシッ」音が鳴れば完成です。</p>

        <p>動作の流れは以下の通りです。</p>
        <ul style="list-style-type: decimal">
          <li><code>XMLHttpRequest();</code> でサーバから音声ファイルを取得する</li>
          <li><code>audioctx.createBufferSource();</code> で用意したバッファに音声データを格納する</li>
          <li><code>src.connect(audioctx.destination);</code> <span class="input-font">audioctx.destination</span> に接続し Node Graph を完成させる</li>
          <li>ボタン操作により、バッファ内のデータを再生する</li>
        </ul>

        <p>ここでは以下のような Node Graph を作ったことになります。</p>
        <div class="flex-center">
          <img src="./images/buffersource.png" class="bordered">
        </div>
        <br>
      </codelab-article>

      <!-- 6 -->
      <codelab-article step_label="ディレイを適用する" duration="5:00">
        <p>「オーディオファイルを鳴らす」よりも眺めのオーディオファイルで動作させてみます。<br><a href="contents/loop.wav"><span class="input-font">loop.wav</span></a> をダウンロードして Chrome Dev Editor の左ペイン内のプロジェクト名（ここでは test_webaudioapi）にドロップしてください。</p>
        <div class="flex-center">
          <img src="./images/webaudio-02.png" width="580" class="bordered">
        </div>

        <p>次に、前の Step で追加したコードを <span class="input-font">index.html</span> から削除してください。まず最初に HTML を追記します。</p>
        <codelab-snippet>
&lt;button id="playsound" disabled>Play&lt;/button>&lt;br/>
&lt;table>
  &lt;tr>&lt;td>Bypass :&lt;/td>&lt;td>&lt;input id="bypass" type="checkbox"/>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>Time : &lt;/td>&lt;td>&lt;input type="text" size="8" id="time" value="0.25"/>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>Feedback : &lt;/td>&lt;td>&lt;input type="text" size="8" id="feedback" value="0.4"/>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>Mix : &lt;/td>&lt;td>&lt;input type="text" size="8" id="mix" value="0.4"/>&lt;/td>&lt;/tr>
&lt;/table></codelab-snippet>
        
        <p>続いて、以下のような Node Graph を作成します。</p>
        <div class="flex-center">
          <img src="./images/delay1.png" class="bordered">
        </div>

        <p class="bottom5px">新しい言葉が出て来たのでその説明です。</p>
        <ul class="top">
          <li><span class="input-font">Dry</span> ： 入力した原音をそのままの出力</li>
          <li><span class="input-font">Wet</span> ： 入力した原音にエフェクトをかけた出力</li>
          <li><span class="input-font">エフェクト</span> ： 原音とは異なった音に変化させること。例えば時間をずらすディレイ、響きを加えるエコー、リバーブなどがあります。</li>
        </ul>

        <p class="bottom5px">それぞれの役割。</p>
        <ul class="top">
          <li><span class="input-font">Gain(Dry)</span> と <span class="input-font">Gain(Wet)</span> ： 入力した原音とエフェクトをかけた音をMixする割合を調整します</li>
          <li><span class="input-font">Delay</span> ： 入力した原音の再生タイミングを遅らせます</li>
          <li><span class="input-font">Gain(Feedback)</span> ： <span class="input-font">Delay</span> で再生タイミングを遅らせた出力の音量を絞り、再び <span class="input-font">Delay</span> に入力します</li>
        </ul>
        
        <codelab-snippet>
&lt;script type="text/javascript">
  var audioctx = new AudioContext();
 
  var buffer = null;
  LoadSample(audioctx, "./loop.wav");
  var src = null;
  var input = audioctx.createGain(); 
  var delay = audioctx.createDelay(); 
  var wetgain = audioctx.createGain(); 
  var drygain = audioctx.createGain(); 
  var feedback = audioctx.createGain(); 

  input.connect(delay);
  input.connect(drygain);
  delay.connect(wetgain);
  delay.connect(feedback);
  feedback.connect(delay);
  wetgain.connect(audioctx.destination);
  drygain.connect(audioctx.destination);

  function LoadSample(ctx, url) {
    var req = new XMLHttpRequest();
    req.open("GET", url, true);
    req.responseType = "arraybuffer";
    req.onload = function () {
      if(req.response) {
        ctx.decodeAudioData(req.response,function(b){buffer=b;},function(){});
        document.querySelector("button#playsound").removeAttribute("disabled");
      }
    }
    req.send();
  }
&lt;/script></codelab-snippet> 

        <p class="bottom5px">Node Graph の説明です。</p>
        <ul class="top">
          <li>入力を <span class="input-font">Delay</span> と <span class="input-font">Gain(Dry)</span>(Dry側のGain) に接続</li>
          <li><span class="input-font">Delay</span> からの出力を <span class="input-font">Gain(Wet)</span>に接続</li>
          <li><span class="input-font">Delay</span> からの出力を <span class="input-font">Gain(Feedback)</span>に接続</li>
          <li><span class="input-font">Gain(Feedback)</span> からの出力を <span class="input-font">Delay</span>に接続</li>
        </ul>

        <p class="bottom5px">最後に、ボタンを押した時の Event Hander を書きます。<br>
「オーディオファイルを鳴らす」では HTML 内に Event Hander を書いていましたが、ここでは JavaScritp から Event Handler を指定する書き方をします。</p>
        <codelab-snippet>
&lt;script type="text/javascript">
  document.querySelector("button#playsound").addEventListener("click", function(event){
    var label; 
    if(event.target.innerHTML=="Stop") {
      src.stop(0);
      label="Start";
    } else {
      src = audioctx.createBufferSource();
      src.buffer = buffer;
      src.loop = true;
      src.connect(input);
      src.start(0);
      label="Stop";
    }
    event.target.innerHTML=label;
  });
  document.querySelector("input#bypass").addEventListener("change", Setup);
  document.querySelector("input#time").addEventListener("change", Setup);
  document.querySelector("input#feedback").addEventListener("change", Setup);
  document.querySelector("input#mix").addEventListener("change", Setup);

  function Setup() {
    var bypass = document.getElementById("bypass").checked;
    delay.delayTime.value = parseFloat(document.getElementById("time").value);
    feedback.gain.value = parseFloat(document.getElementById("feedback").value);
    var mix = parseFloat(document.getElementById("mix").value);
    if(bypass) mix = 0;
      wetgain.gain.value = mix;
      drygain.gain.value = 1 - mix;
  }
  Setup();
&lt;/script></codelab-snippet>

        <p>以上の3つの追記後にアプリケーションを実行し、実行画面内の <button id="step6">Start</button> ボタンをクリックして音声が流れ、画面上のパラメータ、
また ByPass チェックボックスにチェックをつけると ディレイ がからなくなれば完成です。</p>
        <ul class="top">
          <li><span class="input-font">Bypass: <input type="checkbox" id="step6bypass"></span></li> 
        </ul>

        <p>以下の Node はディレイと同じように Node Graph の中に組み込むことでその効果が得られます。</p>
        <ul class="top">
          <li><span class="input-font">PannerNode</span> ： スピーカに音を割り振る</li> 
          <li><span class="input-font">BiquadFilterNode</span> ： フィルタを行う（例えば、低音はカットする等）</li> 
          <li><span class="input-font">GainNode</span> ： 振幅を調整する（音量調節）</li> 
        </ul>

      </codelab-article>


      <!-- 7 -->
      <codelab-article step_label="音声ファイルを可視化する" duration="7:00">
        <p>Web Audio API には入力された音声情報を可視化するためにスペクトラムを取得できる <span class="input-font">Analyser</span> という Node が用意されています。Analyserを使うと簡単に音を可視化することが可能です。まずは音声ファイルの可視化をしてみましょう。</p>
        <p>ここでも「ディレイを適用する」で使用した<a href="contents/loop.wav"><span class="input-font">loop.wav</span></a> を使います。準備していない場合は、ダウンロードして Chrome Dev Editor の左ペイン内のプロジェクト名（ここでは test_webaudioapi）にドロップしてください。</p>
        <div class="flex-center">
          <img src="./images/webaudio-02.png" width="580" class="bordered">
        </div>

        <p>次に、前の Step で追加したコードを <span class="input-font">index.html</span> から削除してください。まず最初に HTML を追記します。</p>
        <codelab-snippet>
&lt;button id="playsound" disabled>Play&lt;/button>&lt;br/>
&lt;table>
  &lt;tr>&lt;td>Frequency/TimeDomain : &lt;/td>&lt;td>&lt;select id="mode" >&lt;option>Frequency&lt;/option>&lt;option>TimeDomain&lt;/option>&lt;/select>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>SmoothingTimeConstant : &lt;/td>&lt;td>&lt;input type="text" id="smoothing" value="0.9"/>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>MinDecibels : &lt;/td>&lt;td>&lt;input type="text" id="min"/>&lt;/td>&lt;/tr>
  &lt;tr>&lt;td>MaxDecibels : &lt;/td>&lt;td>&lt;input type="text" id="max"/>&lt;/td>&lt;/tr>
&lt;/table>
&lt;br/>&lt;br/>
&lt;canvas id="graph" width="512" height="256">&lt;/canvas></codelab-snippet>
        
        <p>入力を原音のまま可視化しますので Node Graph は以下になります。<br>
「オーディオファイルを鳴らす」に <span class="input-font">BufferSource</span> から入力を数値化する <span class="input-font">Analyser</span> への接続を追加しています。
        </p>
        <div class="flex-center">
          <img src="./images/analyser.png" class="bordered">
        </div>

        <p class="bottom5px"><span class="input-font">Analyser</span> に接続してグラフ化する部分を追記します。</p>
        <codelab-snippet>
&lt;script type="text/javascript">
var audioctx = new AudioContext();

var buffer = null;
LoadSample(audioctx, "./loop.wav");
var src = null;
function LoadSample(ctx, url) {
    var req = new XMLHttpRequest();
    req.open("GET", url, true);
    req.responseType = "arraybuffer";
    req.onload = function() {
        if(req.response) {
            ctx.decodeAudioData(req.response,function(b){buffer=b;},function(){});
            document.querySelector("button#playsound").removeAttribute("disabled");
        }
    }
    req.send();
}

var mode = 0;
var timerId;
var analyser = audioctx.createAnalyser();
analyser.fftSize = 1024;
document.getElementById("min").value = analyser.minDecibels;
document.getElementById("max").value = analyser.maxDecibels;
var ctx = document.getElementById("graph").getContext("2d");

function DrawGraph() {
    ctx.fillStyle = "rgba(34, 34, 34, 1.0)";
    ctx.fillRect(0, 0, 512, 256);
    ctx.strokeStyle="rgba(255, 255, 255, 1)";
    var data = new Uint8Array(512);
    if(mode == 0) analyser.getByteFrequencyData(data); //Spectrum Data
    else analyser.getByteTimeDomainData(data); //Waveform Data
    if(mode!=0) ctx.beginPath();
    for(var i = 0; i < 256; ++i) {
        if(mode==0) {
            ctx.fillStyle = "rgba(204, 204, 204, 0.8)";
            ctx.fillRect(i*2, 256 - data[i], 1, data[i]);
        } else {
            ctx.lineTo(i*2, 256 - data[i]);
        }
    }
    if(mode!=0) {
        ctx.stroke();
    }
    requestAnimationFrame(DrawGraph);
}
timerId=requestAnimationFrame(DrawGraph);

function Setup() {
    mode = document.getElementById("mode").selectedIndex;
    analyser.minDecibels = parseFloat(document.getElementById("min").value);
    analyser.maxDecibels = parseFloat(document.getElementById("max").value);
    analyser.smoothingTimeConstant = parseFloat(document.getElementById("smoothing").value);
}
Setup();
&lt;/script></codelab-snippet>

        <p>
          <code>DrawGraph()</code> で描画を行い、<code>DrawGraph()</code> で画面上のパラメータが変更されたときに随時描画に反映させています。描画の流れの説明です。</p>
        <ul style="list-style-type: decimal">
          <li><code>createAnalyser();</code> で <span class="input-font">analyser</span> Nodeを用意します</li>
          <li><span class="input-font">fftSize</span> でFFT（フーリエ変換）のデータサイズを指定します</li>
          <li><code>requestAnimationFrame();</code> でアニメーションのループを動かすことで、イテレーションする度に <span class="input-font">Analyser</span> から数値を取得し、
            その数値を <span class="input-font">canvas</span> 上に描画することで音を可視化しています</li>
        </ul>

        <p class="bottom5px">最後に、ボタンを押した時の Event Hander を書きます。</p>
        <codelab-snippet>
&lt;script type="text/javascript">
document.querySelector("button#playsound").addEventListener("click", function(event){
    var label; 
    if(event.target.innerHTML=="Stop") {
        src.stop(0);
        cancelAnimationFrame(timerId);
        label="Start";
    } else {
        src = audioctx.createBufferSource();
        src.buffer = buffer;
        src.loop = true;
        src.connect(audioctx.destination);
        src.connect(analyser);
        src.start(0);
        label="Stop";
    }
    event.target.innerHTML=label;
});
document.querySelector("select#mode").addEventListener("change", Setup);
document.querySelector("input#smoothing").addEventListener("change", Setup);
document.querySelector("input#min").addEventListener("change", Setup);
document.querySelector("input#max").addEventListener("change", Setup);
&lt;/script></codelab-snippet>
        
        <p>以上の3つの追記後にアプリケーションを実行し、実行画面内の <button id="step7">Start</button> ボタンをクリックして音声が流れ、グラフが表示され、
また <span class="input-font">Frequency/TimeDomain</span> 等のパラメータを更新することで、グラフの表示が変われば成功です。<br>
          <span class="notice-01">※ ここでは、グラフをクリックすることで <span class="input-font">Frequency/TimeDomain</span>（グラフのタイプ）が変わります。</span> 
        </p>
          
        <div class="flex-center">
          <canvas id="step7canvas" class="step7" width="512" height="256"></canvas>
        </div>

      </codelab-article>

      <!-- 8 -->
      <codelab-article step_label="マイク入力を可視化する" duration="6:00">
        <p>次は音声ファイルではなく、コンピュータに接続されているマイクからリアルタイムに入力されてくる音を可視化してみます。</p>

        <p>前の Step の「音声ファイルを可視化する」にコードを追加します。<br/>
        まずは <span class="input-font">index.html</span> に HTML を追記します。お好みの場所に追加してください。</p>
        <codelab-snippet>
&lt;button id="startmic">Start Mic&lt;/button>&lt;br/></codelab-snippet>

        <p>次に JavaScript を追記します。こちらもお好みの場所への追記で構いません。</p>
        <codelab-snippet>
&lt;script type="text/javascript">
var getUserMedia = navigator.getUserMedia ? 'getUserMedia' :
    navigator.webkitGetUserMedia ? 'webkitGetUserMedia' :
    navigator.mozGetUserMedia ? 'mozGetUserMedia' :
    navigator.msGetUserMedia ? 'msGetUserMedia' :
    undefined;
var astream, micsrc;
var conditions={audio:true, video:false};
function Mic() {
    navigator[getUserMedia](
        conditions,
        function(stream) {
            astream=stream;
            micsrc=audioctx.createMediaStreamSource(stream);
            micsrc.connect(audioctx.destination);
            micsrc.connect(analyser);
        },
        function(e) { console.error(e); }
    );
}

// event handler
document.querySelector("button#startmic").addEventListener("click", function(event){
    var label;
    if(event.target.innerHTML=="Start Mic") {
        Mic();
        label="Stop Mic";
    } else {
        astream.stop();
        label="Start Mic";
    }
    event.target.innerHTML=label;
});
&lt;/script></codelab-snippet>

        <p>マイク入力を原音のまま可視化しますので Node Graph は以下になります。</p>
        <div class="flex-center">
          <img src="./images/analyser_mic.png" class="bordered">
        </div>

        <p>動作の流れは以下の通りです。</p>
        <ul style="list-style-type: decimal">
          <li><code>getUserMedia();</code> でコンピュータに接続されたマイクを取得します</li>
          <li><code>audioctx.createMediaStreamSource(stream)</code> で <span class="input-font">stream</span> から Audio Stream を取得します</li>
          <li><code>micsrc.connect(audioctx.destination);</code> 取得した Audio Stream を <span class="input-font">analyser</span> に接続します</li>
          <li><code>micsrc.connect(audioctx.destination);</code> 取得した Audio Stream を <span class="input-font">audioctx.destination</span> に接続し Node Graph を完成させます</li>
          <li>ボタン操作により、マイクからの入力を可視化します</li>
        </ul>
        
        <p>アプリケーションを実行し、実行画面内の <button id="step8">Start Mic</button> ボタンをクリックしてマイクから入力した音声が流れ、グラフが表示され、
また <span class="input-font">Frequency/TimeDomain</span> 等のパラメータを更新することで、グラフの表示が変われば成功です。<br>
          <span class="notice-01">※ ここでは、グラフをクリックすることで <span class="input-font">Frequency/TimeDomain</span>（グラフのタイプ）が変わります。</span> 
        </p>
          
        <div class="flex-center">
          <canvas id="step8canvas" class="step7" width="512" height="256"></canvas>
        </div>

      </codelab-article>


      <!-- 9 -->
      <codelab-article step_label="コンボリューションする" duration="5:00">
        <p>次は音声ファイルにインパルス応答（Impulse Response）を収録した音声ファイルを畳み込む（convolition）ことで原音にエフェクトをかけます。<br>
          Web Audio APIには <span class="input-font">ConvolverNode</span> が用意されていて、この Node をつかことで簡単に実現できます。
        </p>

        <p>インパルス応答を収録したファイル <a href="contents/ir/s1_r1_bd.wav"><span class="input-font">s1_r1_bd.wav</span></a> を使います。ダウンロードして Chrome Dev Editor の左ペイン内のプロジェクト名（ここでは test_webaudioapi）にドロップしてください。</p>
        <div class="flex-center">
          <img src="./images/webaudio-02.png" width="580" class="bordered">
        </div>
        <p>
          <span class="notice-01">※ ここで利用するインパルス応答を収録した <span class="input-font">s1_r1_bd.wav</span> は<a href="http://www.acoustics.hut.fi/projects/poririrs/" taeget="_blank">ココ</a>からダウンロードしたもので非商用利用に限り無料で提供されています。</span> 
        </p>

        <p>まずは前の Step で追加したコードを <span class="input-font">index.html</span> から削除して、以下の HTML を追記します。お好みの場所に追加してください。</p>
        <codelab-snippet>
&lt;button id="playsound" disabled>Start&lt;/button>&lt;br/>
ReverbLevel : &lt;input type="range" id="revlevel" min="0" max="100" value="50"/>
  &lt;span id="revdisp">50&lt;/span></codelab-snippet>

        <p class="bottom5px">次に JavaScript を追記します。</p>
        <codelab-snippet>
&lt;script type="text/javascript">
var audioctx = new AudioContext();
var files = [
    "loop.wav",
    "s1_r1_bd.wav",
];
var source = null;
var convolver = audioctx.createConvolver();
var revlevel = audioctx.createGain();
revlevel.gain.value=0.5;
convolver.connect(revlevel);
revlevel.connect(audioctx.destination);
var buffers = [];
var loadidx = 0;

for(var i=0; i&lt;files.length; i++) {
    LoadSample(audioctx, i);
}
function LoadSample(ctx, idx) {
    var req = new XMLHttpRequest();
    req.open("GET", files[i], true);
    req.responseType = "arraybuffer";
    req.onload = function() {
        if(req.response) {
            ctx.decodeAudioData(req.response,function(b){buffers[idx]=b;},function(){});
            if(files.length==buffers.length) {
                document.querySelector("button#playsound").removeAttribute("disabled");
            }
        }
    }
    req.send();
}
&lt;/script></codelab-snippet>

        <p>音声ファイルの入力を <span class="input-font">Convolver Node</span> で中継して <span class="input-font">destination</span> に接続します。なので、Node Graph は以下になります。</p>
        <div class="flex-center">
          <img src="./images/convolver1.png" class="bordered">
        </div>

        <p class="bottom5px">最後に、ボタンを押した時の Event Hander を書きます。</p>
        <codelab-snippet>
&lt;script type="text/javascript">
document.querySelector("button#playsound").addEventListener("click", function(event){
    var label;
    if(event.target.innerHTML=="Stop") {
        src.stop(0);
        label="Start";
    } else {
        src = audioctx.createBufferSource();
        src.buffer = buffers[0];
        convolver.buffer = buffers[1];
        src.loop = true;
        src.connect(audioctx.destination);
        src.connect(convolver);
        src.start(0);
        label="Stop";
    }
    event.target.innerHTML=label;
});
document.querySelector("input#revlevel").addEventListener("change", function(event){
    var lev=event.target.value;
    revlevel.gain.value=parseInt(lev)*0.01;
    event.target.nextSibling.innerHTML=lev;
});
&lt;/script></codelab-snippet>

        
        <p>アプリケーションを実行し、実行画面内の <button id="step9">Start</button> ボタンをクリックしてマイクから入力した音声が流れ、以下の Slider を動かすことでエフェクトの掛かり具合の調整が行えれば成功です。</p>
        <ul style="list-style-type: none">
          <li><span class="input-font">ReverbLevel : <input type="range" id="step9revlevel" min="0" max="100" value="50" style="width:200px;" class="middle"/><span id="revdisp">50</span></span></li>
        </ul>
        
      </codelab-article>


    </codelab-pack>

    <script src="./js/webaudio-demo.js"></script>
    <script src="register_sw.js"></script>
  </body>
</html>
